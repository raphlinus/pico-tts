# pico-tts

An experiment in making a very simple speech synthesizer.

To run:

```
cargo run out.wav hello
```

On macOS, you can play the generated file using `afplay out.wav`. It wouldn't be hard to wire up sound output using [tinyaudio] or cpal, but I haven't done so.

## Goals and non-goals

Basically, this is an experiment in making the simplest possible speech synthesizer that results in intelligble speech. It does not try to sound natural or particularly high quality.

Another goal is to run in very low-resource environments such as microcontrollers. One motivation was the observation that there are a number of RP2350 based projects that do video out (including [pico-dvi-rs]) but they are missing the ability to do speech output and thus are not accessible to the visually impaired.

This repo is basically an experiment to explore the minimum level of complexity and resource usage to generate intelligible speech. At the moment, there is no effort to make it sound natural, meaning no pitch contours or stress, but improving that could be a future direction.

The general approach is fairly similar to the [GI SP0256] chip. Sound generation is with LPC, using an architecture similar to the [TI chips], but running at 16kHz. Each phoneme is represented as an LPC spectrum plus a small amount of metadata. The spectra were generated by analyzing a sample of my own speech.

## Text to phonemes

There is a very simple text to phoneme engine based on [Elovitz et al]. This is a new implementation based on the paper, with a few tweaks by me and a small dictionary of exceptions.

In its current form, there is no attempt to encode stress or resolve allophones. For long vowels, I've generally chosen a short spelling: IY is i, OW is o, UW is u. I have not made EM/M, EN/N, EL/L, or DX/T distinctions.

## Poor decisions

LPC is conceptually very simple, and it also has the advantage of being straightforward to analyze from a speech source. However, it has some limitations, and in retrospect, the [Klatt] technique would be a better choice.

A major limitation of LPC is that it is not straightforward to adjust the spectrum, for example nudging the formant frequencies to be higher or lower. Another problem is that, while it does fine for vowels, it is less than optimum for nasals and voiced fricatives.

Lastly, while the computational cost of LPC is very low at low sample rates, it scales quadratically as sample rate increases. It's also not possible to adapt the same data to different sample rates. Klatt has neither of these limitations.

Another struggle was the representation of phonemes. I wanted to use IPA including Unicode symbols, partly because it would provide a straightforward path for speaking IPA encoded utterances, but I ran into two problems.

For one, the spelling of diphthongs is controversial. A good introduction is the video [Why these English phonetic symbols are all WRONG] by Geoff Lindsey. For example, IY in ARPABET is traditionally written /iː/, but Lindsey prefers /ɪj/, and similarly for AW: /aʊ/ and /aw/.

I'm also currently not resolving phonemes into allophones, for example T (/t/ in IPA) can be either a flap (/ɾ/) or aspirated (/tʰ/), with many variations. Multiple allophones would be a significant improvement in quality. One potential allophone set is [SP0256 Allophones].

The current version has no implementation of stress, and pitch is monotone. This was an intentional decision to keep things simple, but seriously limits speech quality. Getting prosody right is extremely challenging, but a basic implementation of stress would improve things greatly. See also [Software Automatic Mouth] for pointers on how to do very simple speech variation: pitch is determined from an inverse relation with the F1 formant frequency.

## Future

This was an experiment to explore the simplest possible text to speech synthesizer. The speech quality is disappointing, but might be acceptable as a minimum baseline in some circumstances.

The code hasn't been carefully optimized, but has been designed so that it could be adapted to no_std running on extremely constrained hardware.

The current architecture should probably not be continued. I'm most inclined to switch to Klatt for sound generation.

[pico-dvi-rs]: https://github.com/DusterTheFirst/pico-dvi-rs
[TI chips]: https://en.wikipedia.org/wiki/Texas_Instruments_LPC_Speech_Chips
[Klatt]: https://github.com/espeak-ng/klatt
[IPA]: https://en.wikipedia.org/wiki/International_Phonetic_Alphabet
[Why these English phonetic symbols are all WRONG]: https://www.youtube.com/watch?v=gtnlGH055TA
[ARPABET]: https://en.wikipedia.org/wiki/ARPABET
[Elovitz et al]: https://apps.dtic.mil/sti/pdfs/ADA021929.pdf
[Software Automatic Mouth]: https://en.wikipedia.org/wiki/Software_Automatic_Mouth
[tinyaudio]: https://docs.rs/tinyaudio/latest/tinyaudio/
[cpal]: https://docs.rs/cpal/latest/cpal/
[GI SP0256]: https://en.wikipedia.org/wiki/General_Instrument_SP0256
[SP0256 Allophones]: https://www.cpcwiki.eu/index.php/SP0256_Allophones
